import streamlit as st
import pandas as pd
import numpy as np
from datasets import load_dataset
from sentence_transformers import SentenceTransformer, util
from scipy.stats import pearsonr, spearmanr
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score
import os

st.set_page_config(page_title="Semantic Text Similarity", layout="wide")
st.title("Semantic Text Similarity üåê")
st.write("–°—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ —Å–º—ã—Å–ª–æ–≤–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ—Ç–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (STS, QQP) –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ —Å–≤–æ–∏ CSV.")

# -------------------------
# –ú–æ–¥–µ–ª–∏
# -------------------------
models_available = ["BERT", "RoBERTa", "MiniLM"]

@st.cache_resource
def load_model(name):
    if name == "BERT":
        return SentenceTransformer('bert-base-nli-mean-tokens')
    elif name == "RoBERTa":
        return SentenceTransformer('roberta-base-nli-stsb-mean-tokens')
    else:
        return SentenceTransformer('all-MiniLM-L6-v2')

# ==========================================================
# 1) –í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é
# ==========================================================
st.subheader("–í–≤–æ–¥ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤—Ä—É—á–Ω—É—é")
sent1 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1 –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞", key="manual_sent1")
sent2 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2 –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞", key="manual_sent2")
models_manual = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞:", models_available, default=models_available, key="manual_models")

if st.button("–°—Ä–∞–≤–Ω–∏—Ç—å –≤—Ä—É—á–Ω—É—é", key="manual_compare"):
    if sent1.strip() == "" or sent2.strip() == "":
        st.warning("–í–≤–µ–¥–∏—Ç–µ –æ–±–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
    elif not models_manual:
        st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–æ–¥–µ–ª—å!")
    else:
        results = {}
        for model_name in models_manual:
            model = load_model(model_name)
            emb1 = model.encode(sent1, convert_to_tensor=True)
            emb2 = model.encode(sent2, convert_to_tensor=True)
            similarity = float(util.cos_sim(emb1, emb2))
            results[model_name] = similarity

        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ö–æ–¥—Å—Ç–≤–∞:")
        for name, sim in results.items():
            st.write(f"**{name}**: {sim:.3f}")
            if sim > 0.8:
                st.success("–û—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏")
            elif sim > 0.5:
                st.info("–ß–∞—Å—Ç–∏—á–Ω–æ –ø–æ—Ö–æ–∂–∏")
            else:
                st.warning("–†–∞–∑–Ω—ã–µ –ø–æ —Å–º—ã—Å–ª—É")
        st.bar_chart(results)

# ==========================================================
# 2) –ó–∞–≥—Ä—É–∑–∫–∞ CSV
# ==========================================================
st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (CSV)")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type="csv", key="csv_uploader")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä:")
    st.dataframe(df.head())

    models_csv = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è CSV –¥–∞—Ç–∞—Å–µ—Ç–∞:", models_available, default=models_available, key="csv_models")

    if st.button("–í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è CSV", key="csv_compare"):
        if not all(col in df.columns for col in ["sentence1", "sentence2"]):
            st.error("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'sentence1' –∏ 'sentence2'")
        else:
            results_df = df.copy()
            st.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è... ‚è≥")

            for model_name in models_csv:
                model = load_model(model_name)
                sims = []
                for s1, s2 in zip(df["sentence1"], df["sentence2"]):
                    emb1 = model.encode(s1, convert_to_tensor=True)
                    emb2 = model.encode(s2, convert_to_tensor=True)
                    sims.append(float(util.cos_sim(emb1, emb2)))
                results_df[f"{model_name}_similarity"] = sims

            st.success("–ì–æ—Ç–æ–≤–æ!")
            st.dataframe(results_df.head())

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            if not os.path.exists("data"):
                os.makedirs("data")
            results_df.to_csv("data/results.csv", index=False)
            st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/results.csv")

            # –ú–µ—Ç—Ä–∏–∫–∏
            if "score" in df.columns:
                st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π")
                for model_name in models_csv:
                    y_true = df["score"].values
                    y_pred = np.array(results_df[f"{model_name}_similarity"].values)
                    mse = mean_squared_error(y_true, y_pred)
                    rmse = np.sqrt(mse)
                    pear, _ = pearsonr(y_true, y_pred)
                    spear, _ = spearmanr(y_true, y_pred)
                    st.write(f"**{model_name} ‚Äî –†–µ–≥—Ä–µ—Å—Å–∏—è**: MSE: {mse:.3f}, RMSE: {rmse:.3f}, Pearson: {pear:.3f}, Spearman: {spear:.3f}")

                    # –î–ª—è QQP –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                    if set(y_true) <= {0,1}:
                        threshold = 0.5
                        y_pred_class = (y_pred > threshold).astype(int)
                        accuracy = accuracy_score(y_true, y_pred_class)
                        precision = precision_score(y_true, y_pred_class)
                        recall = recall_score(y_true, y_pred_class)
                        f1 = f1_score(y_true, y_pred_class)
                        st.write(f"**{model_name} ‚Äî –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (QQP)**: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}")

# ==========================================================
# 3) HuggingFace –¥–∞—Ç–∞—Å–µ—Ç—ã
# ==========================================================
st.subheader("–ì–æ—Ç–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (HuggingFace)")
dataset_choice = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:", ["STS Benchmark", "Quora Question Pairs (QQP)"], key="dataset_choice_hf")

if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç", key="load_hf_dataset"):
    if dataset_choice == "STS Benchmark":
        data = load_dataset("stsb_multi_mt", name="en")
        df = data["test"].to_pandas()
        df.rename(columns={"similarity_score": "score"}, inplace=True)
    elif dataset_choice == "Quora Question Pairs (QQP)":
        data = load_dataset("glue", "qqp")
        df = data["validation"].to_pandas()
        df.rename(columns={"question1": "sentence1","question2": "sentence2","label":"score"}, inplace=True)

    st.success(f"{dataset_choice} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
    st.dataframe(df.head())

    models_hf = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è HuggingFace –¥–∞—Ç–∞—Å–µ—Ç–∞:", models_available, default=models_available, key="hf_models_unique")

    if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å HuggingFace –¥–∞—Ç–∞—Å–µ—Ç", key="analyze_hf_dataset"):
        results_df = df.copy()
        st.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è... ‚è≥")

        for model_name in models_hf:
            model = load_model(model_name)
            sims = []
            for s1, s2 in zip(df["sentence1"], df["sentence2"]):
                emb1 = model.encode(s1, convert_to_tensor=True)
                emb2 = model.encode(s2, convert_to_tensor=True)
                sims.append(float(util.cos_sim(emb1, emb2)))
            results_df[f"{model_name}_similarity"] = sims

        st.success("–ì–æ—Ç–æ–≤–æ!")
        st.dataframe(results_df.head())

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        if not os.path.exists("data"):
            os.makedirs("data")
        results_df.to_csv("data/results.csv", index=False)
        st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/results.csv")

        # –ú–µ—Ç—Ä–∏–∫–∏
        st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π")
        for model_name in models_hf:
            y_true = df["score"].values
            y_pred = np.array(results_df[f"{model_name}_similarity"].values)
            mse = mean_squared_error(y_true, y_pred)
            rmse = np.sqrt(mse)
            pear, _ = pearsonr(y_true, y_pred)
            spear, _ = spearmanr(y_true, y_pred)
            st.write(f"**{model_name} ‚Äî –†–µ–≥—Ä–µ—Å—Å–∏—è**: MSE: {mse:.3f}, RMSE: {rmse:.3f}, Pearson: {pear:.3f}, Spearman: {spear:.3f}")

            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è QQP
            if set(y_true) <= {0,1}:
                threshold = 0.5
                y_pred_class = (y_pred > threshold).astype(int)
                accuracy = accuracy_score(y_true, y_pred_class)
                precision = precision_score(y_true, y_pred_class)
                recall = recall_score(y_true, y_pred_class)
                f1 = f1_score(y_true, y_pred_class)
                st.write(f"**{model_name} ‚Äî –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (QQP)**: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}")
