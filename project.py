import streamlit as st
import pandas as pd
from datasets import load_dataset
from sentence_transformers import SentenceTransformer, util
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import pearsonr, spearmanr
import numpy as np
import os

st.set_page_config(page_title="Semantic Text Similarity", layout="wide")
st.title("Semantic Text Similarity üåê")
st.write("""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–º—ã—Å–ª–æ–≤–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.  
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∏ —Ä—É—Å—Å–∫–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã, –≤–≤–æ–¥ –≤—Ä—É—á–Ω—É—é –∏ CSV.
""")

# -------------------------
# –ú–æ–¥–µ–ª–∏
# -------------------------
models_available = {
    "BERT (EN)": "bert-base-nli-mean-tokens",
    "RoBERTa (EN)": "roberta-base-nli-stsb-mean-tokens",
    "MiniLM (Multilingual)": "sentence-transformers/all-MiniLM-L6-v2",
    "RuSBERT (RU)": "sberbank-ai/sbert_large_nlu_ru",
    "mUSE Multilingual": "distiluse-base-multilingual-cased-v2"
}

@st.cache_resource
def load_model(name):
    return SentenceTransformer(models_available[name])

# ==========================================================
# 1) –í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é
# ==========================================================
st.subheader("–í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é")

sent1 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1:", "")
sent2 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2:", "")

manual_models = st.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏:", list(models_available.keys()),
    default=list(models_available.keys()),  # –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    key="manual"
)

if st.button("–°—Ä–∞–≤–Ω–∏—Ç—å"):
    if sent1.strip() == "" or sent2.strip() == "":
        st.error("–í–≤–µ–¥–∏—Ç–µ –æ–±–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
    else:
        results = {}
        for model_name in manual_models:
            model = load_model(model_name)
            emb1 = model.encode(sent1, convert_to_tensor=True)
            emb2 = model.encode(sent2, convert_to_tensor=True)
            sim = float(util.cos_sim(emb1, emb2))
            results[model_name] = sim

        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        for name, sim in results.items():
            st.write(f"**{name}**: {sim:.3f}")
        st.bar_chart(results)

# ==========================================================
# 2) –ó–∞–≥—Ä—É–∑–∫–∞ CSV
# ==========================================================
st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ CSV –¥–∞—Ç–∞—Å–µ—Ç–∞")

uploaded_file = st.file_uploader("CSV —Ñ–∞–π–ª:", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:")
    st.dataframe(df.head())

    csv_models = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏:", list(models_available.keys()),
        default=list(models_available.keys()),  # –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        key="csv"
    )

    if st.button("–ê–Ω–∞–ª–∏–∑ CSV"):
        if not {"sentence1", "sentence2"}.issubset(df.columns):
            st.error("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã: sentence1, sentence2")
        else:
            results_df = df.copy()
            for model_name in csv_models:
                model = load_model(model_name)
                sims = [
                    float(util.cos_sim(
                        model.encode(s1, convert_to_tensor=True),
                        model.encode(s2, convert_to_tensor=True)
                    ))
                    for s1, s2 in zip(df["sentence1"], df["sentence2"])
                ]
                results_df[f"{model_name}_similarity"] = sims

            st.success("–ì–æ—Ç–æ–≤–æ!")
            st.dataframe(results_df.head())

            if not os.path.exists("data"):
                os.makedirs("data")
            results_df.to_csv("data/results.csv", index=False)
            st.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ data/results.csv")

            if "score" in df.columns:
                st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π")
                for model_name in csv_models:
                    y_true = df["score"]
                    y_pred = results_df[f"{model_name}_similarity"]
                    pear = pearsonr(y_true, y_pred)[0]
                    spear = spearmanr(y_true, y_pred)[0]
                    mse = mean_squared_error(y_true, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(y_true, y_pred)
                    r2 = r2_score(y_true, y_pred)

                    st.write(f"""
                    ### {model_name}
                    Pearson: **{pear:.4f}**  
                    Spearman: **{spear:.4f}**  
                    MSE: **{mse:.4f}**  
                    RMSE: **{rmse:.4f}**  
                    MAE: **{mae:.4f}**  
                    R¬≤: **{r2:.4f}**
                    """)

# ==========================================================
# 3) HuggingFace –¥–∞—Ç–∞—Å–µ—Ç—ã
# ==========================================================
st.subheader("–ì–æ—Ç–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (HuggingFace)")

dataset_choice = st.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:",
    ["STS Benchmark (EN)", "Quora Question Pairs (EN)", "RuSTS (RU)"],
    key="hf_ds"
)

if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç"):
    if dataset_choice == "STS Benchmark (EN)":
        data = load_dataset("stsb_multi_mt", name="en")["test"]
        df = data.to_pandas()
        df.rename(columns={"similarity_score": "score"}, inplace=True)

    elif dataset_choice == "Quora Question Pairs (EN)":
        data = load_dataset("glue", "qqp")["validation"]
        df = data.to_pandas()
        df.rename(columns={
            "question1": "sentence1",
            "question2": "sentence2",
            "label": "score"
        }, inplace=True)

    elif dataset_choice == "RuSTS (RU)":
        data = load_dataset("mteb/RuSTSBenchmarkSTS", split="test")
        df = data.to_pandas()

    st.success("–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω!")
    st.dataframe(df.head())

    hf_models = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏:", list(models_available.keys()),
        default=list(models_available.keys()),  # –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        key="hf_models"
    )

    if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç"):
        results_df = df.copy()
        for model_name in hf_models:
            model = load_model(model_name)
            sims = [
                float(util.cos_sim(
                    model.encode(s1, convert_to_tensor=True),
                    model.encode(s2, convert_to_tensor=True)
                ))
                for s1, s2 in zip(df["sentence1"], df["sentence2"])
            ]
            results_df[f"{model_name}_similarity"] = sims

        st.success("–ì–æ—Ç–æ–≤–æ!")
        st.dataframe(results_df.head())

        if not os.path.exists("data"):
            os.makedirs("data")
        results_df.to_csv("data/results_hf.csv", index=False)
        st.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ data/results_hf.csv")

        st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)")
        for model_name in hf_models:
            y_true = df["score"]
            y_pred = results_df[f"{model_name}_similarity"]

            pear = pearsonr(y_true, y_pred)[0]
            spear = spearmanr(y_true, y_pred)[0]
            mse = mean_squared_error(y_true, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_true, y_pred)
            r2 = r2_score(y_true, y_pred)

            st.write(f"""
            ### {model_name}
            Pearson: **{pear:.4f}**  
            Spearman: **{spear:.4f}**  
            MSE: **{mse:.4f}**  
            RMSE: **{rmse:.4f}**  
            MAE: **{mae:.4f}**  
            R¬≤: **{r2:.4f}**
            """)
