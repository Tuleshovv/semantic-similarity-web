import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score
from scipy.stats import pearsonr, spearmanr
import os

# -------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# -------------------------
st.set_page_config(page_title="Semantic Text Similarity", layout="wide")
st.title("Semantic Text Similarity üåê")
st.write("–°—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ —Å–º—ã—Å–ª–æ–≤–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é MiniLM –º–æ–¥–µ–ª–∏.")

# -------------------------
# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (MiniLM)
# -------------------------
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# -------------------------
# 1) –í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é
# -------------------------
st.subheader("–í–≤–æ–¥ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤—Ä—É—á–Ω—É—é")
sent1 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1", key="manual1")
sent2 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2", key="manual2")

if st.button("–°—Ä–∞–≤–Ω–∏—Ç—å –≤—Ä—É—á–Ω—É—é", key="compare_manual"):
    if sent1.strip() == "" or sent2.strip() == "":
        st.warning("–í–≤–µ–¥–∏—Ç–µ –æ–±–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
    else:
        emb1 = model.encode(sent1, convert_to_tensor=True)
        emb2 = model.encode(sent2, convert_to_tensor=True)
        similarity = float(util.cos_sim(emb1, emb2))
        st.write(f"Cosine Similarity: **{similarity:.3f}**")
        if similarity > 0.8:
            st.success("–û—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏")
        elif similarity > 0.5:
            st.info("–ß–∞—Å—Ç–∏—á–Ω–æ –ø–æ—Ö–æ–∂–∏")
        else:
            st.warning("–†–∞–∑–Ω—ã–µ –ø–æ —Å–º—ã—Å–ª—É")

# -------------------------
# 2) –ó–∞–≥—Ä—É–∑–∫–∞ CSV
# -------------------------
st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ CSV")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'sentence1' –∏ 'sentence2' (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ 'score')", type="csv", key="csv_upload")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:")
    st.dataframe(df.head())

    if st.button("–í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è CSV", key="csv_calc"):
        if not all(col in df.columns for col in ["sentence1", "sentence2"]):
            st.error("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'sentence1' –∏ 'sentence2'")
        else:
            sims = []
            for s1, s2 in zip(df["sentence1"], df["sentence2"]):
                emb1 = model.encode(s1, convert_to_tensor=True)
                emb2 = model.encode(s2, convert_to_tensor=True)
                sims.append(float(util.cos_sim(emb1, emb2)))
            df["similarity"] = sims
            st.success("–í—ã—á–∏—Å–ª–µ–Ω–æ —Å—Ö–æ–¥—Å—Ç–≤–æ!")
            st.dataframe(df.head())

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if not os.path.exists("data"):
                os.makedirs("data")
            df.to_csv("data/results.csv", index=False)
            st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/results.csv")

            # -------------------------
            # –ú–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'score'
            # -------------------------
            if "score" in df.columns:
                st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏")

                y_true = df["score"].values
                y_pred = np.array(sims)

                # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
                mse = mean_squared_error(y_true, y_pred)
                rmse = np.sqrt(mse)
                pear, _ = pearsonr(y_true, y_pred)
                spear, _ = spearmanr(y_true, y_pred)

                st.write("**–†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:**")
                st.write(f"MSE: {mse:.3f}")
                st.write(f"RMSE: {rmse:.3f}")
                st.write(f"Pearson: {pear:.3f}")
                st.write(f"Spearman: {spear:.3f}")

                # –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–¥–ª—è QQP: score 0/1)
                if set(y_true) <= {0,1}:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º similarity –≤ –∫–ª–∞—Å—Å—ã –ø–æ –ø–æ—Ä–æ–≥—É
                    threshold = 0.5
                    y_pred_class = (y_pred > threshold).astype(int)

                    accuracy = accuracy_score(y_true, y_pred_class)
                    precision = precision_score(y_true, y_pred_class)
                    recall = recall_score(y_true, y_pred_class)
                    f1 = f1_score(y_true, y_pred_class)

                    st.write("**–ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (QQP):**")
                    st.write(f"Accuracy: {accuracy:.3f}")
                    st.write(f"Precision: {precision:.3f}")
                    st.write(f"Recall: {recall:.3f}")
                    st.write(f"F1-score: {f1:.3f}")
