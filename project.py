import streamlit as st
import pandas as pd
from datasets import load_dataset
from sentence_transformers import SentenceTransformer, util
from scipy.stats import pearsonr, spearmanr
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score
import numpy as np
import os

# ------------------------- Streamlit Setup -------------------------
st.set_page_config(page_title="Semantic Text Similarity", layout="wide")
st.title("Semantic Text Similarity ðŸŒ")
st.write("Ð¡Ñ€Ð°Ð²Ð½Ð¸Ð²Ð°Ð¹Ñ‚Ðµ ÑÐ¼Ñ‹ÑÐ»Ð¾Ð²Ð¾Ðµ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ€ÑƒÑ‡Ð½Ð¾Ð¹ Ð²Ð²Ð¾Ð´, CSV Ð¸Ð»Ð¸ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹ STS Ð¸ QQP.")

# ------------------------- Model Loader -------------------------
models_available = ["BERT", "RoBERTa", "MiniLM"]

@st.cache_resource
def load_model(name):
    if name == "BERT":
        return SentenceTransformer('bert-base-nli-mean-tokens')
    elif name == "RoBERTa":
        return SentenceTransformer('roberta-base-nli-stsb-mean-tokens')
    else:
        return SentenceTransformer('all-MiniLM-L6-v2')


# ==========================================================
# 1) Ð Ð£Ð§ÐÐžÐ™ Ð’Ð’ÐžÐ”
# ==========================================================
st.subheader("Ð’Ð²Ð¾Ð´ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ")

sent1 = st.text_area("ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ 1", "")
sent2 = st.text_area("ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ 2", "")

models_manual = st.multiselect(
    "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸:", 
    models_available, 
    default=models_available
)

if st.button("Ð¡Ñ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ"):
    if not sent1.strip() or not sent2.strip():
        st.warning("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¾Ð±Ð° Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ!")
    else:
        results = {}
        for model_name in models_manual:
            model = load_model(model_name)
            emb1 = model.encode(sent1, convert_to_tensor=True)
            emb2 = model.encode(sent2, convert_to_tensor=True)
            sim = float(util.cos_sim(emb1, emb2))
            results[model_name] = sim

            st.write(f"### {model_name}: {sim:.3f}")

        st.bar_chart(results)


# ==========================================================
# 2) Ð—ÐÐ“Ð Ð£Ð—ÐšÐ CSV
# ==========================================================
st.subheader("Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° (CSV)")

uploaded_file = st.file_uploader("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ CSV Ñ„Ð°Ð¹Ð»", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.dataframe(df.head())

    models_csv = st.multiselect(
        "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ CSV:",
        models_available,
        default=models_available
    )

    if st.button("Ð’Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÑŒ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ CSV"):
        if not all(x in df.columns for x in ["sentence1", "sentence2"]):
            st.error("CSV Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ sentence1 Ð¸ sentence2")
        else:
            results_df = df.copy()
            st.info("Ð Ð°Ð±Ð¾Ñ‚Ð°ÐµÐ¼... â³")

            for model_name in models_csv:
                model = load_model(model_name)
                sims = []
                for s1, s2 in zip(df["sentence1"], df["sentence2"]):
                    emb1 = model.encode(s1, convert_to_tensor=True)
                    emb2 = model.encode(s2, convert_to_tensor=True)
                    sims.append(float(util.cos_sim(emb1, emb2)))
                results_df[f"{model_name}_similarity"] = sims

            st.success("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!")
            st.dataframe(results_df.head())

            if not os.path.exists("data"):
                os.makedirs("data")
            results_df.to_csv("data/results.csv", index=False)
            st.info("Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð² data/results.csv")

            # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ score
            if "score" in df.columns:
                st.subheader("ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
                metrics_list = []

                for model_name in models_csv:
                    sim = results_df[f"{model_name}_similarity"]
                    pear, _ = pearsonr(df["score"], sim)
                    spear, _ = spearmanr(df["score"], sim)
                    mse = mean_squared_error(df["score"], sim)
                    rmse = np.sqrt(mse)

                    st.write(f"""
                    ### {model_name}
                    **Pearson:** {pear:.3f}  
                    **Spearman:** {spear:.3f}  
                    **MSE:** {mse:.4f}  
                    **RMSE:** {rmse:.4f}  
                    """)

                    metrics_list.append({
                        "Model": model_name,
                        "Pearson": pear,
                        "Spearman": spear,
                        "MSE": mse,
                        "RMSE": rmse
                    })

                st.bar_chart(pd.DataFrame(metrics_list).set_index("Model"))


# ==========================================================
# 3) HUGGINGFACE DATASETS (STS, QQP)
# ==========================================================
st.subheader("Ð“Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹ HuggingFace")

dataset_choice = st.selectbox(
    "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚:",
    ["STS Benchmark", "Quora Question Pairs (QQP)"]
)

if st.button("Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚"):
    if dataset_choice == "STS Benchmark":
        data = load_dataset("stsb_multi_mt", name="en")
        df = data["test"].to_pandas()
        df.rename(columns={"similarity_score": "score"}, inplace=True)

    elif dataset_choice == "Quora Question Pairs (QQP)":
        data = load_dataset("glue", "qqp")
        df = data["validation"].to_pandas()
        df.rename(columns={
            "question1": "sentence1",
            "question2": "sentence2",
            "label": "score"
        }, inplace=True)

    st.success("Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾!")
    st.dataframe(df.head())

    models_hf = st.multiselect(
        "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸:",
        models_available,
        default=models_available
    )


    # -------------- ÐÐ½Ð°Ð»Ð¸Ð· ------------------
    if st.button("ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ HuggingFace Ð´Ð°Ñ‚Ð°ÑÐµÑ‚"):
        results_df = df.copy()
        st.info("Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð°...")

        for model_name in models_hf:
            model = load_model(model_name)
            sims = []
            for s1, s2 in zip(df["sentence1"], df["sentence2"]):
                emb1 = model.encode(s1, convert_to_tensor=True)
                emb2 = model.encode(s2, convert_to_tensor=True)
                sims.append(float(util.cos_sim(emb1, emb2)))
            results_df[f"{model_name}_similarity"] = sims

        st.success("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!")
        st.dataframe(results_df.head())

        if not os.path.exists("data"):
            os.makedirs("data")
        results_df.to_csv("data/results.csv", index=False)
        st.info("Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð² data/results.csv")

        # -------- ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ --------
        st.subheader("ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        metrics_list = []

        for model_name in models_hf:
            sim = results_df[f"{model_name}_similarity"]

            pear, _ = pearsonr(df["score"], sim)
            spear, _ = spearmanr(df["score"], sim)
            mse = mean_squared_error(df["score"], sim)
            rmse = np.sqrt(mse)

            metrics = {
                "Model": model_name,
                "Pearson": pear,
                "Spearman": spear,
                "MSE": mse,
                "RMSE": rmse
            }

            # ---- ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ QQP ----
            if dataset_choice == "Quora Question Pairs (QQP)":
                pred = (sim > 0.5).astype(int)
                true = df["score"]

                acc = accuracy_score(true, pred)
                prec = precision_score(true, pred, zero_division=0)
                rec = recall_score(true, pred, zero_division=0)
                f1 = f1_score(true, pred, zero_division=0)

                metrics.update({
                    "Accuracy": acc,
                    "Precision": prec,
                    "Recall": rec,
                    "F1": f1
                })

                st.write(f"""
                ### {model_name}
                **Pearson:** {pear:.3f}  
                **Spearman:** {spear:.3f}  
                **MSE:** {mse:.4f}  
                **RMSE:** {rmse:.4f}  
                **Accuracy:** {acc:.3f}  
                **Precision:** {prec:.3f}  
                **Recall:** {rec:.3f}  
                **F1-score:** {f1:.3f}  
                """)

            else:
                st.write(f"""
                ### {model_name}
                **Pearson:** {pear:.3f}  
                **Spearman:** {spear:.3f}  
                **MSE:** {mse:.4f}  
                **RMSE:** {rmse:.4f}  
                """)

            metrics_list.append(metrics)

        st.bar_chart(pd.DataFrame(metrics_list).set_index("Model"))
