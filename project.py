import streamlit as st
import pandas as pd
from datasets import load_dataset
from sentence_transformers import SentenceTransformer, util, InputExample, losses
from torch.utils.data import DataLoader
from scipy.stats import pearsonr, spearmanr
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import os

st.set_page_config(page_title="Semantic Text Similarity + Train", layout="wide")
st.title("Semantic Text Similarity üåê —Å –æ–±—É—á–µ–Ω–∏–µ–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏")

# -------------------------
# –ú–æ–¥–µ–ª–∏
# -------------------------
models_available = [
    "MiniLM (Multilingual)",
    "MiniLM L12 (Multilingual)",
    "DistilBERT (EN)",
    "RuSBERT (RU)",
    "XLM-R (Multilingual)"
]

@st.cache_resource
def load_model(name):
    if name == "MiniLM (Multilingual)":
        return SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
    elif name == "MiniLM L12 (Multilingual)":
        return SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')
    elif name == "DistilBERT (EN)":
        return SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')
    elif name == "RuSBERT (RU)":
        return SentenceTransformer('sberbank-ai/sbert_large_nlu_ru')
    elif name == "XLM-R (Multilingual)":
        return SentenceTransformer('sentence-transformers/xlm-r-bert-base-nli-stsb-mean-tokens')

# ==========================================================
# 1) –í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é
# ==========================================================
st.subheader("–í–≤–æ–¥ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤—Ä—É—á–Ω—É—é")
sent1 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1", "")
sent2 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2", "")
models_manual = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏:", models_available, default=models_available, key="manual_models")

if st.button("–°—Ä–∞–≤–Ω–∏—Ç—å –≤—Ä—É—á–Ω—É—é"):
    if sent1.strip() == "" or sent2.strip() == "":
        st.warning("–í–≤–µ–¥–∏—Ç–µ –æ–±–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
    else:
        results = {}
        for model_name in models_manual:
            model = load_model(model_name)
            emb1 = model.encode(sent1, convert_to_tensor=True)
            emb2 = model.encode(sent2, convert_to_tensor=True)
            similarity = float(util.cos_sim(emb1, emb2))
            results[model_name] = similarity

        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ö–æ–¥—Å—Ç–≤–∞:")
        for name, sim in results.items():
            st.write(f"**{name}**: {sim:.3f}")
        st.bar_chart(results)

# ==========================================================
# 2) –ó–∞–≥—Ä—É–∑–∫–∞ CSV
# ==========================================================
st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (CSV)")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type="csv", key="csv_uploader")

if uploaded_file:
    df_csv = pd.read_csv(uploaded_file)
    st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä CSV:")
    st.dataframe(df_csv.head())

    models_csv = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è CSV:", models_available, default=models_available, key="csv_models")

    if st.button("–í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è CSV"):
        if not all(col in df_csv.columns for col in ["sentence1", "sentence2"]):
            st.error("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'sentence1' –∏ 'sentence2'")
        else:
            results_df = df_csv.copy()
            st.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞... ‚è≥")

            for model_name in models_csv:
                model = load_model(model_name)
                sims = []
                for s1, s2 in zip(df_csv["sentence1"], df_csv["sentence2"]):
                    emb1 = model.encode(s1, convert_to_tensor=True)
                    emb2 = model.encode(s2, convert_to_tensor=True)
                    sims.append(float(util.cos_sim(emb1, emb2)))
                results_df[f"{model_name}_similarity"] = sims

            st.success("–ì–æ—Ç–æ–≤–æ!")
            st.dataframe(results_df.head())

            if not os.path.exists("data"):
                os.makedirs("data")
            results_df.to_csv("data/results.csv", index=False)
            st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/results.csv")

            # –ú–µ—Ç—Ä–∏–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å score
            if "score" in df_csv.columns:
                st.subheader("Regression Metrics")
                metrics_list = []
                for model_name in models_csv:
                    y_true = df_csv["score"]
                    y_pred = results_df[f"{model_name}_similarity"]
                    pear = pearsonr(y_true, y_pred)[0]
                    spear = spearmanr(y_true, y_pred)[0]
                    mse = mean_squared_error(y_true, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(y_true, y_pred)
                    r2 = r2_score(y_true, y_pred)
                    metrics_list.append({
                        "Model": model_name,
                        "Pearson": pear,
                        "Spearman": spear,
                        "MSE": mse,
                        "RMSE": rmse,
                        "MAE": mae,
                        "R2": r2
                    })
                    st.write(f"**{model_name}** ‚Äî Pearson: {pear:.3f}, Spearman: {spear:.3f}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, MAE: {mae:.3f}, R¬≤: {r2:.3f}")

                st.bar_chart(pd.DataFrame(metrics_list).set_index("Model"))

# ==========================================================
# 3) HuggingFace –¥–∞—Ç–∞—Å–µ—Ç—ã –∏ –æ–±—É—á–µ–Ω–∏–µ
# ==========================================================
st.subheader("HuggingFace –¥–∞—Ç–∞—Å–µ—Ç—ã –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
dataset_choice = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:", ["STS Benchmark (EN)", "RuSTS (RU)"])

if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç"):
    if dataset_choice == "STS Benchmark (EN)":
        data = load_dataset("stsb_multi_mt", name="en")
        df = data["train"].to_pandas()
        df.rename(columns={"sentence1":"sentence1","sentence2":"sentence2","similarity_score":"score"}, inplace=True)
        df["score"] = df["score"] / 5.0  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è 0-1
    else:
        data = load_dataset("ai-forever/ru-sts")["train"]
        df = data.to_pandas()
        df.rename(columns={"sentence1":"sentence1","sentence2":"sentence2","similarity_score":"score"}, inplace=True)
        df["score"] = df["score"] / 5.0

    st.success(f"{dataset_choice} –∑–∞–≥—Ä—É–∂–µ–Ω! –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")
    st.dataframe(df.head())

    model_to_train = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:", models_available, key="train_model")
    epochs = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö:", min_value=1, max_value=10, value=3, step=1)

    if st.button("–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"):
        st.info("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏... ‚è≥")
        model = load_model(model_to_train)

        # –°–æ–∑–¥–∞–Ω–∏–µ InputExample
        train_examples = [InputExample(texts=[row["sentence1"], row["sentence2"]], label=row["score"]) 
                          for _, row in df.iterrows()]

        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)
        train_loss = losses.CosineSimilarityLoss(model=model)

        # Fine-tuning
        model.fit(
            train_objectives=[(train_dataloader, train_loss)],
            epochs=epochs,
            warmup_steps=100
        )

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        save_path = f"models/{model_to_train.replace(' ', '_')}_finetuned"
        if not os.path.exists("models"):
            os.makedirs("models")
        model.save(save_path)
        st.success(f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_path}")
        st.info("–¢–µ–ø–µ—Ä—å –µ—ë –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –∏–ª–∏ CSV!")

