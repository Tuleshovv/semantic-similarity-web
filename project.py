import streamlit as st
import pandas as pd
from datasets import load_dataset
from sentence_transformers import SentenceTransformer, util
from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score
from scipy.stats import pearsonr, spearmanr
import numpy as np
import os

st.set_page_config(page_title="Semantic Text Similarity", layout="wide")
st.title("Semantic Text Similarity üåê")
st.write("–°—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ —Å–º—ã—Å–ª–æ–≤–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º BERT –∏ RoBERTa.")

# -------------------------
# –ú–æ–¥–µ–ª–∏
# -------------------------
models_available = ["BERT", "RoBERTa"]

@st.cache_resource
def load_model(name):
    if name == "BERT":
        return SentenceTransformer('bert-base-nli-mean-tokens')
    else:
        return SentenceTransformer('roberta-base-nli-stsb-mean-tokens')

# ==========================================================
# 1) –í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é
# ==========================================================
st.subheader("–í–≤–æ–¥ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤—Ä—É—á–Ω—É—é")
sent1 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1", "")
sent2 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2", "")
models_manual = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏:", models_available, default=models_available, key="manual_models")

if st.button("–°—Ä–∞–≤–Ω–∏—Ç—å –≤—Ä—É—á–Ω—É—é"):
    if sent1.strip() == "" or sent2.strip() == "":
        st.warning("–í–≤–µ–¥–∏—Ç–µ –æ–±–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
    elif not models_manual:
        st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–æ–¥–µ–ª—å!")
    else:
        results = {}
        for model_name in models_manual:
            model = load_model(model_name)
            emb1 = model.encode(sent1, convert_to_tensor=True, normalize_embeddings=True)
            emb2 = model.encode(sent2, convert_to_tensor=True, normalize_embeddings=True)
            similarity = float(util.cos_sim(emb1, emb2))
            results[model_name] = similarity

        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ö–æ–¥—Å—Ç–≤–∞:")
        for name, sim in results.items():
            st.write(f"**{name}**: {sim:.3f}")
            if sim > 0.8:
                st.success("–û—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏")
            elif sim > 0.5:
                st.info("–ß–∞—Å—Ç–∏—á–Ω–æ –ø–æ—Ö–æ–∂–∏")
            else:
                st.warning("–†–∞–∑–Ω—ã–µ –ø–æ —Å–º—ã—Å–ª—É")

        st.bar_chart(results)

# ==========================================================
# 2) –ó–∞–≥—Ä—É–∑–∫–∞ CSV
# ==========================================================
st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (CSV)")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type="csv", key="csv_uploader")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä:")
    st.dataframe(df.head())

    models_csv = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è CSV:", models_available, default=models_available, key="csv_models")

    if st.button("–í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è CSV"):
        if not all(col in df.columns for col in ["sentence1", "sentence2"]):
            st.error("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'sentence1' –∏ 'sentence2'")
        else:
            results_df = df.copy()
            st.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞... ‚è≥")

            for model_name in models_csv:
                model = load_model(model_name)
                sims = []
                for s1, s2 in zip(df["sentence1"], df["sentence2"]):
                    emb1 = model.encode(s1, convert_to_tensor=True, normalize_embeddings=True)
                    emb2 = model.encode(s2, convert_to_tensor=True, normalize_embeddings=True)
                    sims.append(float(util.cos_sim(emb1, emb2)))
                results_df[f"{model_name}_similarity"] = sims

            st.success("–ì–æ—Ç–æ–≤–æ!")
            st.dataframe(results_df.head())

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–∫–∞—á–∞—Ç—å
            if not os.path.exists("data"):
                os.makedirs("data")
            results_df.to_csv("data/results.csv", index=False)
            st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/results.csv")

            st.download_button(
                label="–°–∫–∞—á–∞—Ç—å CSV —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏",
                data=results_df.to_csv(index=False).encode('utf-8'),
                file_name='results.csv',
                mime='text/csv',
            )

            # –ú–µ—Ç—Ä–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ü–µ–Ω–∫–∞)
            if "score" in df.columns:
                st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)")
                for model_name in models_csv:
                    mse = mean_squared_error(df["score"], results_df[f"{model_name}_similarity"])
                    rmse = np.sqrt(mse)
                    pear, _ = pearsonr(df["score"], results_df[f"{model_name}_similarity"])
                    spear, _ = spearmanr(df["score"], results_df[f"{model_name}_similarity"])
                    st.write(f"**{model_name}** ‚Äî MSE: {mse:.3f}, RMSE: {rmse:.3f}, Pearson: {pear:.3f}, Spearman: {spear:.3f}")

            if "label" in df.columns:
                st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)")
                for model_name in models_csv:
                    pred = np.round(results_df[f"{model_name}_similarity"].values)
                    accuracy = accuracy_score(df["label"], pred)
                    precision = precision_score(df["label"], pred)
                    recall = recall_score(df["label"], pred)
                    f1 = f1_score(df["label"], pred)
                    st.write(f"**{model_name}** ‚Äî Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}")





