import streamlit as st
import pandas as pd
import numpy as np
import os
from datasets import load_dataset
from sentence_transformers import SentenceTransformer, InputExample, losses, util
from torch.utils.data import DataLoader
from scipy.stats import pearsonr, spearmanr

st.set_page_config(page_title="Semantic Text Similarity üî•", layout="wide")
st.title("Semantic Text Similarity —Å –æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ üåê")

# -------------------------
# –ú–æ–¥–µ–ª–∏
# -------------------------
models_available = ["BERT", "RoBERTa", "MiniLM"]

@st.cache_resource
def load_model(name):
    if name == "BERT":
        return SentenceTransformer('bert-base-nli-mean-tokens')
    elif name == "RoBERTa":
        return SentenceTransformer('roberta-base-nli-stsb-mean-tokens')
    else:
        return SentenceTransformer('all-MiniLM-L6-v2')

# ==========================================================
# 1) –í–≤–æ–¥ –≤—Ä—É—á–Ω—É—é
# ==========================================================
st.subheader("–í–≤–æ–¥ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤—Ä—É—á–Ω—É—é")
sent1 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1", "")
sent2 = st.text_area("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2", "")
models_manual = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏:", models_available, default=models_available, key="manual_models")

if st.button("–°—Ä–∞–≤–Ω–∏—Ç—å –≤—Ä—É—á–Ω—É—é"):
    if sent1.strip() == "" or sent2.strip() == "":
        st.warning("–í–≤–µ–¥–∏—Ç–µ –æ–±–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
    else:
        results = {}
        for model_name in models_manual:
            model = load_model(model_name)
            emb1 = model.encode(sent1, convert_to_tensor=True)
            emb2 = model.encode(sent2, convert_to_tensor=True)
            sim = float(util.cos_sim(emb1, emb2))
            results[model_name] = sim

        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ö–æ–¥—Å—Ç–≤–∞:")
        for name, sim in results.items():
            st.write(f"**{name}**: {sim:.3f}")
            if sim > 0.8:
                st.success("–û—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏")
            elif sim > 0.5:
                st.info("–ß–∞—Å—Ç–∏—á–Ω–æ –ø–æ—Ö–æ–∂–∏")
            else:
                st.warning("–†–∞–∑–Ω—ã–µ –ø–æ —Å–º—ã—Å–ª—É")
        st.bar_chart(results)

# ==========================================================
# 2) CSV –∏–ª–∏ HuggingFace –¥–∞—Ç–∞—Å–µ—Ç
# ==========================================================
st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ –≤—ã–±–æ—Ä HuggingFace")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV", type="csv", key="csv_uploader")
dataset_choice = st.selectbox("–ò–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ HuggingFace –¥–∞—Ç–∞—Å–µ—Ç", ["None", "STS Benchmark", "Quora Question Pairs (QQP)"], key="hf_choice")
models_dataset = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞:", models_available, default=models_available, key="dataset_models")

df = None

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä CSV:")
    st.dataframe(df.head())

elif dataset_choice != "None":
    if dataset_choice == "STS Benchmark":
        data = load_dataset("stsb_multi_mt", name="en")
        df = data["test"].to_pandas()
        df.rename(columns={"sentence1": "sentence1", "sentence2": "sentence2", "similarity_score": "score"}, inplace=True)
    elif dataset_choice == "Quora Question Pairs (QQP)":
        data = load_dataset("glue", "qqp")
        df = data["validation"].to_pandas()
        df.rename(columns={"question1": "sentence1", "question2": "sentence2", "label": "score"}, inplace=True)
    st.success(f"{dataset_choice} –∑–∞–≥—Ä—É–∂–µ–Ω!")
    st.dataframe(df.head())

# ==========================================================
# 3) –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
# ==========================================================
if df is not None:
    st.subheader("–û–±—É—á–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ")
    train_model_name = st.selectbox("–ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è", models_available, key="train_model")
    epochs = st.number_input("–≠–ø–æ—Ö–∏", min_value=1, max_value=5, value=1)
    batch_size = st.number_input("Batch size", min_value=4, max_value=64, value=16)

    if st.button("–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"):
        model = load_model(train_model_name)
        st.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        train_examples = [InputExample(texts=[row["sentence1"], row["sentence2"]], label=float(row["score"])/5.0)
                          for _, row in df.iterrows()]
        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)
        train_loss = losses.CosineSimilarityLoss(model)

        st.info("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è... ‚è≥")
        model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=epochs, warmup_steps=50)
        st.success("–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")

        # ==========================================================
        # 4) –†–∞—Å—á–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
        # ==========================================================
        results_df = df.copy()
        st.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ...")
        sims = []
        for s1, s2 in zip(df["sentence1"], df["sentence2"]):
            emb1 = model.encode(s1, convert_to_tensor=True)
            emb2 = model.encode(s2, convert_to_tensor=True)
            sims.append(float(util.cos_sim(emb1, emb2)))
        results_df[f"{train_model_name}_similarity"] = sims
        st.success("–ì–æ—Ç–æ–≤–æ!")
        st.dataframe(results_df.head())

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        if not os.path.exists("data"):
            os.makedirs("data")
        results_df.to_csv("data/results.csv", index=False)
        st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/results.csv")

        # –ú–µ—Ç—Ä–∏–∫–∏
        if "score" in df.columns:
            st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏")
            pear, _ = pearsonr(df["score"], results_df[f"{train_model_name}_similarity"])
            spear, _ = spearmanr(df["score"], results_df[f"{train_model_name}_similarity"])
            st.write(f"**{train_model_name}** ‚Äî Pearson: {pear:.3f}, Spearman: {spear:.3f}")
